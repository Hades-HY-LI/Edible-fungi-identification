# Quick note about ResNet: larger image dataset with 1M+ photos and 1K+ classes

# TODO: also can try pretrained = False to retrain the resnet18 model from scratch
# should be worse than the pretrained=True as ~3000 images are still considered as small data set
model_ft = models.resnet18(pretrained=True)
num_ftrs = model_ft.fc.in_features
# Here the size of each output sample is set to 2.
# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).
model_ft.fc = nn.Linear(num_ftrs, 2)

model_ft = model_ft.to(device)

# TODO: could try another loss funciton, e.g. focal loss for classification
criterion = nn.CrossEntropyLoss()

# Observe that all parameters are being optimized
# Note to use a relatively small starting learning rate, otherwise pretrained models weights are updated drastically
# i.e. we do not benefit from the existing
# TODO: could try another optimizer, e.g. Adam
optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)

# Decay LR by a factor of 0.1 every 7 epochs
# TODO: could change lr_scheduler based on the epoch loss
exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)

# TODO: could increase the number of epochs
model_ft_1, epoch_loss_1, epoch_acc_1, poison_identified_1, epoch_recall_1 = train_model(model_ft, criterion, optimizer_ft,exp_lr_scheduler,num_epochs=25)


# Save the entire model
# Specify a path
PATH = "entire_model_1.pt"

# Save
torch.save(model_ft_1, PATH)

# Load
# model = torch.load(PATH)
# model.eval()

# from the numpy module
np.savetxt("epoch_loss_18.csv", 
           epoch_loss_1,
           delimiter =", ", 
           fmt ='% s')

# from the numpy module
np.savetxt("epoch_acc_18.csv", 
           epoch_acc_1,
           delimiter =", ", 
           fmt ='% s')

# from the numpy module
np.savetxt("epoch_recall_18.csv", 
           epoch_recall_1,
           delimiter =", ", 
           fmt ='% s')

# resnet34
model_ft = models.resnet34(pretrained=True)
num_ftrs = model_ft.fc.in_features
# Here the size of each output sample is set to 2.
# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).
model_ft.fc = nn.Linear(num_ftrs, 2)

model_ft = model_ft.to(device)

criterion = nn.CrossEntropyLoss()
optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)
# Decay LR by a factor of 0.1 every 7 epochs
exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)

# TODO: could increase the number of epochs
model_ft_2, epoch_loss_2, epoch_acc_2, poison_identified_2, epoch_recall_2 = train_model(model_ft, criterion, optimizer_ft,exp_lr_scheduler,num_epochs=25)

# Save the entire model
# Specify a path
PATH = "entire_model_net34.pt"

# Save
torch.save(model_ft_2, PATH)

# Load
# model = torch.load(PATH)
# model.eval()

# from the numpy module
np.savetxt("epoch_loss_34.csv", 
           epoch_loss_2,
           delimiter =", ", 
           fmt ='% s')

# from the numpy module
np.savetxt("epoch_acc_34.csv", 
           epoch_acc_2,
           delimiter =", ", 
           fmt ='% s')

# from the numpy module
np.savetxt("epoch_recall_34.csv", 
           epoch_recall_2,
           delimiter =", ", 
           fmt ='% s')

# resnet152
model_ft = models.resnet152(pretrained=True)
num_ftrs = model_ft.fc.in_features
model_ft.fc = nn.Linear(num_ftrs, 2)

model_ft = model_ft.to(device)

criterion = nn.CrossEntropyLoss()
optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)
# Decay LR by a factor of 0.1 every 7 epochs
exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)

model_ft_3, epoch_loss_3, epoch_acc_3, poison_identified_3, epoch_recall_3 = train_model(model_ft, criterion,optimizer_ft,exp_lr_scheduler,num_epochs=25)

# Save the entire model
# Specify a path
PATH = "entire_model_net152.pt"

# Save
torch.save(model_ft_3, PATH)

# Load
# model = torch.load(PATH)
# model.eval()

# from the numpy module
np.savetxt("epoch_loss_152.csv", 
           epoch_loss_3,
           delimiter =", ", 
           fmt ='% s')

# from the numpy module
np.savetxt("epoch_acc_152.csv", 
           epoch_acc_3,
           delimiter =", ", 
           fmt ='% s')

# from the numpy module
np.savetxt("epoch_recall_152.csv", 
           epoch_recall_3,
           delimiter =", ", 
           fmt ='% s')

visualize_model_test(model_ft_1, 6)
visualize_model_test(model_ft_2, 6)
visualize_model_test(model_ft_3, 6)

test_acc_1 = test_model(model_ft_1)
test_acc_2 = test_model(model_ft_2)
test_acc_3 = test_model(model_ft_3)


model_ft = models.resnet18(pretrained=True)
#model_ft = models.resnet34(pretrained=True)
num_ftrs = model_ft.fc.in_features
model_ft.fc = nn.Linear(num_ftrs, 2)
model_ft = model_ft.to(device)

# criterion = nn.CrossEntropyLoss()
criterion = FocalLoss(gamma=5)
optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)
# optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.001)  # Adam optimizer
exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)

model_ft, Epoch_loss, Epoch_acc,_ ,_ = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,
                       num_epochs=25)

visualize_model(model_ft)


PATH = "entire_model_net152.pt"
# Load finetuned ResNet152 model
model152_ft = torch.load(PATH, map_location=torch.device(device))
model152_ft.eval()

# Confusion matrix for ResNet152
cm152 = confusion_matrix(model152_ft, 2)
# cols are predicted labels (left to right): edible, poisonous
# rows are true labels (left to right): edible, poisonous
print(cm152)

plot_confusion_matrix(cm152.numpy(), class_names, title='Confusion matrix for ResNet152', normalize=False)

PATH = "entire_model_net34.pt"

# Load finetuned ResNet34 model
model34_ft = torch.load(PATH, map_location=torch.device(device))
model34_ft.eval()

# Confusion matrix for ResNet34
cm34 = confusion_matrix(model34_ft, 2)
print(cm34)
plot_confusion_matrix(cm34.numpy(), class_names, title='Confusion matrix for ResNet34', normalize=False)

PATH = "entire_model_net18.pt"
# Load finetuned ResNet18 model
model18_ft = torch.load(PATH, map_location=torch.device(device))
model18_ft.eval()

# Confusion matrix for ResNet18
cm18 = confusion_matrix(model18_ft, 2)
print(cm18)
plot_confusion_matrix(cm18.numpy(), class_names, title='Confusion matrix for ResNet18', normalize=False)





